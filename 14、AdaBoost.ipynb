{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> boosting方法的核心理念在于博采众长，正所谓\"三个臭皮匠，顶个诸葛亮\"，这也使得boosting方法要好于大多数单模型算法。一般来说，boosting方法都要解答两个关键问题：一是在训练过程中如何改变训练样本的权重或者是概率分布，二是如何将多个弱分类器组合成一个强分类器。针对这两个问题，Adaboost是做法非常朴素，第一个就是提高前一轮被弱分类器分类错误的样本的权重、而降低分类正确的样本权重；第二则是对多个弱分类器进行线性组合，提高分类效果好的弱分类器权重，减小分类误差率大的弱分类器权重。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](28.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](29.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](30.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先定义一个决策树桩，本质上就是一个带有阈值划分的决策树结点。\n",
    "class DecisionStump():\n",
    "    def __init__(self):\n",
    "        # 基于划分阈值决定样本分类为1还是-1\n",
    "        self.polarity = 1\n",
    "        # 特征索引\n",
    "        self.feature_index = None\n",
    "        # 特征划分阈值\n",
    "        self.threshold = None\n",
    "        # 指示分类准确率的值\n",
    "        self.alpha = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaboost():\n",
    "    # 弱分类器个数\n",
    "    def __init__(self, n_estimators=5):\n",
    "        self.n_estimators = n_estimators\n",
    "    # Adaboost拟合算法\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # (1) 初始化权重分布为均匀分布 1/N\n",
    "        w = np.full(n_samples, (1/n_samples)) #full.填充同一值为给定大小\n",
    "        \n",
    "        self.estimators = []\n",
    "        # (2) for m in (1,2,...,M)\n",
    "        for _ in range(self.n_estimators):\n",
    "            # (2.a) 训练一个弱分类器：决策树桩\n",
    "            clf = DecisionStump()\n",
    "            # 设定一个最小化误差\n",
    "            min_error = float('inf')\n",
    "            # 遍历数据集特征，根据最小分类误差率选择最优划分特征\n",
    "            for feature_i in range(n_features):\n",
    "                feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "                unique_values = np.unique(feature_values)\n",
    "                # 尝试将每一个特征值作为分类阈值\n",
    "                for threshold in unique_values:\n",
    "                    p = 1\n",
    "                    # 初始化所有预测值为1\n",
    "                    prediction = np.ones(np.shape(y))\n",
    "                    # 小于分类阈值的预测值为-1\n",
    "                    prediction[X[:, feature_i] < threshold] = -1\n",
    "                    # 2.b 计算误差率\n",
    "                    error = sum(w[y != prediction])\n",
    "                    \n",
    "                    # 如果分类误差大于0.5，则进行正负预测翻转考虑到标签打反？\n",
    "                    # E.g error = 0.8 => (1 - error) = 0.2\n",
    "                    if error > 0.5:\n",
    "                        error = 1 - error\n",
    "                        p = -1\n",
    "\n",
    "                    # 一旦获得最小误差则保存相关参数配置\n",
    "                    if error < min_error:\n",
    "                        clf.polarity = p # 极性\n",
    "                        clf.threshold = threshold #每个特征中的分界线\n",
    "                        clf.feature_index = feature_i #那个特征名\n",
    "                        min_error = error\n",
    "                        \n",
    "            # 2.c 计算基分类器的权重\n",
    "            clf.alpha = 0.5 * math.log((1.0 - min_error) / (min_error + 1e-10)) #G(x)，最后的基分类器权重，也用于更新样本权重\n",
    "            # 初始化所有预测值为1\n",
    "            predictions = np.ones(np.shape(y))\n",
    "            # 获取所有小于阈值的负类索引\n",
    "            negative_idx = (clf.polarity * X[:, clf.feature_index] < clf.polarity * clf.threshold)\n",
    "            # 将负类设为 '-1'\n",
    "            predictions[negative_idx] = -1 #更新y？对，就是在更新按这个分类器分类的结果   \n",
    "            # 2.d 更新样本权重\n",
    "            w *= np.exp(-clf.alpha * y * predictions)\n",
    "            w /= np.sum(w)\n",
    "\n",
    "            # 保存该弱分类器\n",
    "            self.estimators.append(clf)\n",
    "    \n",
    "    # 定义预测函数\n",
    "    def predict(self, X):\n",
    "        n_samples = np.shape(X)[0]\n",
    "        y_pred = np.zeros((n_samples, 1))\n",
    "        # 计算每个弱分类器的预测值\n",
    "        for clf in self.estimators:\n",
    "            # 初始化所有预测值为1\n",
    "            predictions = np.ones(np.shape(y_pred))\n",
    "            # 获取所有小于阈值的负类索引\n",
    "            negative_idx = (clf.polarity * X[:, clf.feature_index] < clf.polarity * clf.threshold)\n",
    "            # 将负类设为 '-1'\n",
    "            predictions[negative_idx] = -1\n",
    "            # 2.e 对每个弱分类器的预测结果进行加权\n",
    "            y_pred += clf.alpha * predictions\n",
    "\n",
    "        # 返回最终预测结果\n",
    "        y_pred = np.sign(y_pred).flatten()\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets.load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "digit1 = 1\n",
    "digit2 = 8\n",
    "idx = np.append(np.where(y==digit1)[0], np.where(y==digit2)[0])\n",
    "y = data.target[idx]\n",
    "# Change labels to {-1, 1}\n",
    "y[y == digit1] = -1\n",
    "y[y == digit2] = 1\n",
    "X = data.data[idx]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用5个弱分类器\n",
    "clf = Adaboost(n_estimators=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
